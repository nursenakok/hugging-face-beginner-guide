{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAPnVnh1uybw+i04QbNqoF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nursenakok/hugging-face-beginner-guide/blob/main/Tokenizer_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-trained Tokenizer**\n"
      ],
      "metadata": {
        "id": "taIt3AIc7rir"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3k-hQaNz7hDs"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\") # Load a pre-trained tokenizer for a specific model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUyXjCIY8TTF",
        "outputId": "4ea8eec8-ad1e-459a-c454-a53689c974c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Quantum physics reveals the strange behavior of particles at tiny scales, which challenges our understanding of reality.\""
      ],
      "metadata": {
        "id": "F_AEtyj38loy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.tokenize(sentence) #Tokenization – splitting text into tokens (words or subwords)\n",
        "print (tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_6b38eB9Ctv",
        "outputId": "e71ddc3c-7c7d-4c2d-8161-5fdb0b4f4351"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Quantum', 'physics', 'reveals', 'the', 'strange', 'behavior', 'of', 'particles', 'at', 'tiny', 'scales', ',', 'which', 'challenges', 'our', 'understanding', 'of', 'reality', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(sentence) # Converting tokens to IDs with special tokens – mapping each token to its integer ID from the model vocabulary.\n",
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28CHqpV19dX-",
        "outputId": "c73e9c2a-1687-4999-83a8-227926194862"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 25231, 7094, 7189, 1103, 4020, 4658, 1104, 9150, 1120, 4296, 9777, 117, 1134, 7806, 1412, 4287, 1104, 3958, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmSQv2ce92OV",
        "outputId": "1923f524-44be-41ea-d790-61cfda39efad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25231, 7094, 7189, 1103, 4020, 4658, 1104, 9150, 1120, 4296, 9777, 117, 1134, 7806, 1412, 4287, 1104, 3958, 119]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode = tokenizer.decode(token_ids) # Decoding tokens back to text – showing how token IDs can be converted back to readable text\n",
        "print(decode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmlNzSNJ97dP",
        "outputId": "edd02316-f8b5-4c2c-c69f-9c949e874890"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantum physics reveals the strange behavior of particles at tiny scales, which challenges our understanding of reality.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(101) # Special tokens; at the beginning (used for sequence-level tasks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4DCoe8nr9dbI",
        "outputId": "6da7dec9-a227-47a0-f57f-a202c85b82af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(102) # Special tokens; at the end (used for separating sentences in pair tasks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Y1o7KYN09dfT",
        "outputId": "37723d8b-da91-47ef-c964-d9c19360524e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(sentence, padding=\"max_length\", max_length=25, return_tensors=\"pt\") #Attention mask – indicating which tokens the model should focus on and which are padding\n",
        "print(inputs[\"input_ids\"])\n",
        "print(inputs[\"attention_mask\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoI8x07EJRaw",
        "outputId": "03b75f93-6e7c-4c4c-eba6-3abfa236bbf8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101, 25231,  7094,  7189,  1103,  4020,  4658,  1104,  9150,  1120,\n",
            "          4296,  9777,   117,  1134,  7806,  1412,  4287,  1104,  3958,   119,\n",
            "           102,     0,     0,     0,     0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if we choose another model with same sentence"
      ],
      "metadata": {
        "id": "WFuwU2ZG9dh8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer2 = AutoTokenizer.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "id": "9wq4b2tF9dkc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids2 = tokenizer2(sentence)\n",
        "print(input_ids2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-kq4dht9dnI",
        "outputId": "e11cbeaf-2887-4efc-f71f-7b42a37d44f1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [0, 44572, 783, 17759, 7441, 5, 7782, 3650, 9, 16710, 23, 5262, 21423, 6, 61, 2019, 84, 2969, 9, 2015, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens2 = tokenizer2.tokenize(sentence)\n",
        "print (tokens2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wEvkq1yBOwh",
        "outputId": "fa1c1f74-928d-4fa7-ceb8-602dc53f7901"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Quant', 'um', 'Ġphysics', 'Ġreveals', 'Ġthe', 'Ġstrange', 'Ġbehavior', 'Ġof', 'Ġparticles', 'Ġat', 'Ġtiny', 'Ġscales', ',', 'Ġwhich', 'Ġchallenges', 'Ġour', 'Ġunderstanding', 'Ġof', 'Ġreality', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer2.decode(0)   # RoBERTa special token: <s>\n",
        "                       # Marks the start of a sequence (similar to BERT's [CLS])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4nvABV5J9dr8",
        "outputId": "c3b9fcc6-91bf-49df-b6ca-c2c9e9333cbf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer2.decode(2) # RoBERTa special token: </s>\n",
        "                     # Marks the end of a sequence or separates sentences (similar to BERT's [SEP])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7VwbJpEDBgOz",
        "outputId": "27d4a37c-d541-4ca5-a0e6-ad54e64f5c47"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}